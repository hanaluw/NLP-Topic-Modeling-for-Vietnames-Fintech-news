{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanaluw/NLP-Topic-Modeling-for-Vietnames-Fintech-news/blob/main/Bertopic_with_ctfidf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V5iK7xrPkFt6"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install sentence_transformers\n",
        "# !pip install pandas openpyxl  # đọc excel\n",
        "!pip install -U bertopic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "ZT-XPp4R_WTS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFHugGhKkIvO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('/content/trial2018only.xlsx')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zprgObFQeBtz"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZicSqPNhqd9S"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def clean1(text):\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return \"\"\n",
        "    text = re.sub(r\"[“”‘’…\\\"']\", \" \", text)  # Remove special quotes\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize whitespace\n",
        "    return text\n",
        "\n",
        "# Apply cleaning only to valid strings\n",
        "df['title'] = df['title'].astype(str).apply(clean1)\n",
        "df['content'] = df['content'].astype(str).apply(clean1)\n",
        "\n",
        "# Remove rows with empty content or title after cleaning\n",
        "df = df[(df['title'].str.strip() != \"\") & (df['content'].str.strip() != \"\")]\n",
        "\n",
        "# Convert to list for later use\n",
        "title = df[\"title\"].tolist()\n",
        "content = df[\"content\"].tolist()\n",
        "\n",
        "# Ensure date column is datetime\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")  # coerce invalid formats to NaT\n",
        "df = df[df[\"date\"].notna()]  # Drop rows where date conversion failed\n",
        "timestamps = df[\"date\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K37jg_0kuJ7"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# Create folder in Drive\n",
        "folder_path = \"/content/drive/MyDrive/Fintech_BERTopic\"\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "# Save all data in one file\n",
        "data = {\n",
        "    \"title\": df[\"title\"].tolist(),\n",
        "    \"content\": df[\"content\"].tolist(),\n",
        "    \"timestamps\": df[\"date\"].tolist()\n",
        "}\n",
        "\n",
        "with open(f\"{folder_path}/text_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH49gvzUlGHn"
      },
      "source": [
        "##load content back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bj0OO7Okzj9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Fintech_BERTopic/text_data.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "title = data[\"title\"]\n",
        "content = data[\"content\"]\n",
        "timestamps = data[\"timestamps\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YiE1ILzl23X_"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Tải tokenizer của mô hình\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dangvantuan/vietnamese-document-embedding\", trust_remote_code=True)\n",
        "\n",
        "# Tìm số token của mỗi văn bản\n",
        "token_lengths = [len(tokenizer.encode(text, truncation=False)) for text in content]\n",
        "\n",
        "# Tìm chiều dài lớn nhất và chỉ số của văn bản đó\n",
        "max_length = max(token_lengths)\n",
        "max_index = token_lengths.index(max_length)\n",
        "\n",
        "print(f\"Chiều dài lớn nhất (số token): {max_length}\")\n",
        "print(f\"Văn bản dài nhất ở chỉ số: {max_index}\")\n",
        "\n",
        "# Kiểm tra có bị cắt không\n",
        "if max_length > 8192:\n",
        "    print(\"\\n Văn bản này vượt quá giới hạn 8192 tokens ⇒ sẽ bị cắt khi embed.\")\n",
        "else:\n",
        "    print(\"\\n Văn bản nằm trong giới hạn ⇒ sẽ không bị cắt.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyDEfaqaqFWQ"
      },
      "source": [
        "#Pre-calculate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yjvVZ6QOrF1a"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('dangvantuan/vietnamese-document-embedding', trust_remote_code=True, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1-HbQVdrmHV"
      },
      "outputs": [],
      "source": [
        "embeddings = model.encode(content, batch_size=16, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDZDmFODxnHT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# After computing embeddings\n",
        "np.save('fintechembeddings.npy', embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNrUraZpiciU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3goWXW5irsz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/BERTopc_Light\"\n",
        "os.makedirs(folder_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRixUdW6i4DX"
      },
      "outputs": [],
      "source": [
        "np.save(f\"{folder_path}/fintechembeddings.npy\", embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjf-VW_Tk_AV"
      },
      "source": [
        "##load embeddings back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgWi3ayDkLf4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the embeddings\n",
        "embeddings = np.load('/content/fintechembeddings.npy')\n",
        "\n",
        "# Optional: check shape\n",
        "print(embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59ihhVFWpuRR"
      },
      "source": [
        "# Dimensionality reduction + Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1NEAaVypo3I"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "umap_model = UMAP(\n",
        "    n_neighbors=30,\n",
        "    n_components=5,\n",
        "    min_dist=0.05,\n",
        "    metric='cosine',\n",
        "    random_state=42,\n",
        "    low_memory=True,\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE9OjzOmptL5"
      },
      "outputs": [],
      "source": [
        "from hdbscan import HDBSCAN\n",
        "hdbscan_model = HDBSCAN(\n",
        "    min_cluster_size=15,            # Minimum number of docs in a topic\n",
        "    metric='euclidean',             # Works well with UMAP (cosine already applied in UMAP)\n",
        "    cluster_selection_method='eom', # Standard for well-separated clusters\n",
        "    prediction_data=True,           # Needed if you plan to update or visualize\n",
        "    core_dist_n_jobs=-1             # Use all CPU cores\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpMDLeZ03SE9"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xFjx-w7MvXIX"
      },
      "outputs": [],
      "source": [
        "!pip install underthesea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUzpzOuSyn5n"
      },
      "outputs": [],
      "source": [
        "from underthesea import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs-V25C_5S9D"
      },
      "outputs": [],
      "source": [
        "vietnamese_stopwords = [\n",
        "    \"và\", \"của\", \"là\", \"có\", \"cho\", \"trong\", \"được\", \"với\", \"một\", \"những\",\n",
        "    \"các\", \"đã\", \"đang\", \"đến\", \"này\", \"từ\", \"ra\", \"vào\", \"nếu\", \"cũng\",\n",
        "    \"như\", \"làm\", \"khi\", \"thì\", \"vì\", \"tại\", \"vậy\", \"nhưng\", \"để\", \"cần\",\n",
        "    \"qua\", \"nên\", \"sau\", \"đó\", \"vẫn\", \"nhiều\", \"năm\", \"đi\", \"đó\", \"ai\",\n",
        "    \"bao\", \"bằng\", \"chỉ\", \"có thể\", \"giữa\", \"hay\", \"kẻ\", \"không\", \"lại\",\n",
        "    \"lên\", \"lúc\", \"mà\", \"nào\", \"nữa\", \"phải\", \"qua\", \"ra\", \"rằng\", \"rất\",\n",
        "    \"tất cả\", \"thế\", \"thấy\", \"theo\", \"thì\", \"trên\", \"trước\", \"tuy\", \"và\",\n",
        "    \"vậy\", \"vì\", \"với\", \"đã\", \"đang\", \"đến\", \"điều\", \"đó\", \"được\", \"đây\",\n",
        "    \"đó\", \"để\", \"ở\", \"ở đây\", \"ở đó\", \"ấy\", \"ấy là\", \"đừng\", \"không\", \"này\",\n",
        "    \"này là\", \"đều\", \"như\", \"đến\", \"bởi\", \"đã\", \"làm\", \"ra\", \"với\",\"người\",\n",
        "    \"ông\",\"bà\",\"có\",\"đây\",\"bị\",\"khi\",\"là\",\"của\",\"tại\",\"và\",\"do\",\"theo\",\"với\",\"hơn\",\n",
        "    \"trong\",\"về\",\"một\",\"những\",\"ngoài_ra\",\"cũng\",\"đã\",\"rằng\",\"trên\",\"đó\",\n",
        "    \"không\",\"chỉ\",\"nhưng\",\"như\",\"các\",\"sẽ\",\"cùng\",\"còn\",\"giúp\",\"được\",\"nếu\",\n",
        "    \"dù\",\"mà\",\"qua\",\"bên_cạnh_đó\",\"tuy_nhiên\",\"song\",\"bởi\",\"như_vậy\",\n",
        "    \"đồng_thời\",\"vậy_nên\",\"bởi_vậy\",\"bởi_vì\",\"thế_nên\",\"thế_nhưng\",\"đâu\",\n",
        "    \"đâu_đó\",\"tất_cả\",\"điều_này\",\"việc_này\",\"này\",\"ấy\",\"nào\",\"gì\",\"vậy\",\"thế\",\n",
        "    \"rất\",\"cả\",\"mỗi\",\"hết\",\"bất_cứ\",\"mọi\",\"tuy\",\"mỗi_khi\",\"hễ\",\"thật\",\"quả_thật\",\n",
        "    \"chính\",\"gần\",\"xa\",\"hết_sức\",\"cực_kỳ\",\"vô_cùng\",\"lắm\",\"quá\",\"bao_nhiêu\",\n",
        "    \"nhiều\",\"ít\",\"nào_đó\",\"mình\",\"cho\",\"việc\",\"tin\",\"mức\",\"đầu\",\"cuối\",\"phải\",\n",
        "    \"lên\",\"lớn\",\"số\",\"ra\",\"biết\",\"gửi\",\"đạt\",\"cần\",\"vụ\",\"đi\",\"tới\",\"mang\",\"rõ\",\n",
        "    \"cách\",\"phương\",\"cuộc\",\"cạnh\",\"thành\",\"đủ\",\"gồm\",\"tiếp_tục\",\"sử_dụng\",\"nhận\",\n",
        "    \"lần\",\"nhóm\",\"lượng\",\"trả\",\"tuần\",\"nói\",\"vừa\",\"%\",\"+\",\"-\",\"*\",\"/\",\"=\",\"<\",\">\",\n",
        "    \"&\",\"tôi\",\",\",\".\",\"(\",\")\",\":\",\";\",\"bạn\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U110c5VW28Q-"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Faster tokenizer using underthesea\n",
        "def tokenize_vi(text):\n",
        "    return word_tokenize(text, format=\"text\").split()\n",
        "\n",
        "vectorizer_model = CountVectorizer(\n",
        "    tokenizer=tokenize_vi,\n",
        "    stop_words=vietnamese_stopwords,\n",
        "    min_df=3, #minimum document frequency threshold\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=30000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdHLlHxE_v7l"
      },
      "outputs": [],
      "source": [
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ4awPTK6htj"
      },
      "source": [
        "#BERTopic training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFhCe17Q6luV"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic(\n",
        "\n",
        "  # Pipeline models\n",
        "  embedding_model=model,\n",
        "  umap_model=umap_model,\n",
        "  hdbscan_model=hdbscan_model,\n",
        "  vectorizer_model=vectorizer_model,\n",
        "  ctfidf_model=ctfidf_model,\n",
        "\n",
        "  # Hyperparameters\n",
        "  top_n_words=50, #Show top 30 most relevant words .get_topic_info()\n",
        "  verbose=True\n",
        ")\n",
        "\n",
        "topics, probs = topic_model.fit_transform(content, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeUxYaiRfdMS"
      },
      "source": [
        "#LET'S GET STARTED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEYIUzP25njr"
      },
      "outputs": [],
      "source": [
        "# In ra 10 topic phổ biến nhất\n",
        "topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0_aH-oZ9QUW"
      },
      "outputs": [],
      "source": [
        "rep_docs = topic_model.representative_docs_\n",
        "\n",
        "# Create a map from doc text to title for quick lookup\n",
        "doc_to_title = {doc_text: doc_title for doc_text, doc_title in zip(content, title)}\n",
        "\n",
        "# Print representative docs + their titles by topic\n",
        "for topic_id, docs in rep_docs.items():\n",
        "    print(f\"Topic {topic_id}:\")\n",
        "    for doc_text in docs:\n",
        "        doc_title = doc_to_title.get(doc_text, \"Title not found\")\n",
        "        print(f\"  Title: {doc_title}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_ctfidf_similarity_scores(topic_model, docs, topics):\n",
        "    # Bước 1: Lấy vectorizer và mô hình c-TF-IDF\n",
        "    vectorizer = topic_model.vectorizer_model\n",
        "    ctfidf_model = topic_model.ctfidf_model\n",
        "\n",
        "    # Bước 2: Transform văn bản thành BoW rồi c-TF-IDF vector\n",
        "    X_bow = vectorizer.transform(docs)\n",
        "    X_ctfidf = ctfidf_model.transform(X_bow)\n",
        "\n",
        "    # Bước 3: Lấy ma trận c-TF-IDF của các topic\n",
        "    topic_ctfidf = topic_model.c_tf_idf_\n",
        "    topic_info = topic_model.get_topic_info()\n",
        "    topic_id_to_index = {tid: i for i, tid in enumerate(topic_info[\"Topic\"].tolist())}\n",
        "\n",
        "    # Bước 4: Tính similarity giữa mỗi văn bản với topic được gán\n",
        "    similarity_scores = []\n",
        "    for i in range(len(docs)):\n",
        "        topic_id = topics[i]\n",
        "        if topic_id == -1 or topic_id not in topic_id_to_index:\n",
        "            similarity_scores.append(None)\n",
        "        else:\n",
        "            topic_index = topic_id_to_index[topic_id]\n",
        "            doc_vec = X_ctfidf[i]\n",
        "            topic_vec = topic_ctfidf[topic_index]\n",
        "            sim = cosine_similarity(doc_vec, topic_vec)[0][0]\n",
        "            similarity_scores.append(sim)\n",
        "\n",
        "    return similarity_scores"
      ],
      "metadata": {
        "id": "x9QbaFAtDSH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_scores = get_ctfidf_similarity_scores(topic_model, content, topics)\n",
        "\n",
        "df_similarity = pd.DataFrame({\n",
        "    \"Title\": title,\n",
        "    \"Assigned Topic\": topics,\n",
        "    \"Similarity to Topic (c-TF-IDF)\": similarity_scores\n",
        "})\n"
      ],
      "metadata": {
        "id": "-OqBvB2DFlFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEIEdYjQgCZ8"
      },
      "outputs": [],
      "source": [
        "df_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_similarity.to_excel(\"similarity_scores.xlsx\", index=False, engine=\"openpyxl\")"
      ],
      "metadata": {
        "id": "QTNc08mgF8Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load for visual"
      ],
      "metadata": {
        "id": "Icbcq8SH_bFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iWS5K0kSGGPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/BERTopic_Light\"\n",
        "print(os.listdir(folder_path))"
      ],
      "metadata": {
        "id": "-6FUOQAO-qSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic"
      ],
      "metadata": {
        "id": "WWXW8fhP-yVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = BERTopic.load(\"/content/drive/MyDrive/BERTopic_Light\")"
      ],
      "metadata": {
        "id": "gGfdvB83--VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.visualize_hierarchy()"
      ],
      "metadata": {
        "id": "BtYpY1ld_7iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 =loaded_model.visualize_hierarchy()\n",
        "fig1.write_html(\"/content/hierarchy_final.html\")\n",
        "fig1"
      ],
      "metadata": {
        "id": "B0WI519nAHkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_IqBqvg7Ahn_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python (fintech_topic)",
      "language": "python",
      "name": "fintech_topic"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}